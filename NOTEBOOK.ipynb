{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import lyricsgenius\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import duden\n",
    "import time\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Lyrics\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- API Schlüssel und Zugangsdaten einsetzen\n",
    "- Playlist IDs von Spotify suchen \n",
    "- Jeder Track der Playlist wird auf LyricsGenius gesucht\n",
    "- Sollte zu einem Song kein Lyrics gefunden werden, wird die Anzahl hochgezählt\n",
    "- Es wird eine JSON Datei gebildet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPOTIPY_CLIENT_ID = '46da6046625f409cb53ab06bf807861d'\n",
    "SPOTIPY_CLIENT_SECRET = '00efb0ab68db4f1eaf27ec53a4c1e068'\n",
    "GENIUS_ACCESS_TOKEN = 'OsBvEsJ_OLKYR42CJoaA_N97GNOS44XXFk4KPPcLtCYnWmDwnnzY2RpcG_SdG25a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id = '2siI2ILJEPr88yibWLgQQl'  #Playlist: \"Deutsche Songs die jeder kennt ;)\"\n",
    "playlist_id = '37i9dQZF1DWTWEW1zqSeEj' #Playlist: Zurück in die 90er\n",
    "playlist_id ='56r5qRUv3jSxADdmBkhcz7' # Playlist: Top Hits of 2022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausführen von getlyrics.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./all_songs.json\") as f:\n",
    "    songs_dict = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ausführen von cyspa.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(songs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:28<00:00,  3.09it/s]\n",
      "100%|██████████| 43/43 [00:11<00:00,  3.74it/s]\n",
      "100%|██████████| 88/88 [00:25<00:00,  3.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#NEU #Spacy muss gedownloaded werden mit : pip install -U pip setuptools wheel   und    pip install spacy \n",
    "#de_core_news_sm-3.5.0-py3-none-any.whl (muss gedownloaded werden -> https://spacy.io/models/de/)\n",
    "#de_core_news_lg-3.5.0-py3-none-any.whl\n",
    "#de_dep_news_trf-3.5.0-py3-none-any.whl\n",
    "\n",
    "nlp = spacy.load(\"de_core_news_sm\")\n",
    "#nlp1 = spacy.load (\"de_dep_news_trf\")\n",
    "nlp2 = spacy.load (\"de_core_news_lg\")\n",
    "\n",
    "list_of_nouns, list_of_pronouns = [],[]\n",
    "\n",
    "def spacify_with_coref(lyrics_from_song):\n",
    "    doc3 = nlp2(lyrics_from_song)\n",
    "    doc = nlp(lyrics_from_song)\n",
    "\n",
    "    doc._.coref_chains = doc3._.coref_chains\n",
    "\n",
    "    return doc\n",
    "\n",
    "for playlist in songs_dict.keys():\n",
    "    list_of_nouns_playlist, list_of_pronouns_playlist = [], []\n",
    "    for song_id in tqdm(songs_dict[playlist].keys()):\n",
    "\n",
    "        lyrics_from_song = songs_dict[playlist][song_id][\"lyrics\"]\n",
    "        doc = nlp(lyrics_from_song)\n",
    "        #doc2 = nlp1 (lyrics_from_song)\n",
    "        doc3 = nlp2 (lyrics_from_song)\n",
    "\n",
    "        # Ausgabe lediglich von Wörtern, die Nomen und Pronomen sind:\n",
    "        for token in doc3: \n",
    "            if token.pos_ == \"NOUN\":\n",
    "                list_of_nouns_playlist.append(token.text)\n",
    "            elif token.pos_ == \"PRON\":\n",
    "                list_of_pronouns_playlist.append(token.text)\n",
    "            else:\n",
    "                pass\n",
    "    list_of_nouns.append(list_of_nouns_playlist)\n",
    "    list_of_pronouns.append(list_of_pronouns_playlist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List in Json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json in Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_dict = {name: list_ for name, list_ in zip(songs_dict.keys(), list_of_nouns)}\n",
    "lop_dict = {name: list_ for name, list_ in zip(songs_dict.keys(), list_of_pronouns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 nouns were found.\n",
      "3 pronouns were found.\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(list_of_nouns)} nouns were found.\")\n",
    "print(f\"{len(list_of_pronouns)} pronouns were found.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Daten sortieren\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOMEN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Json-Datei wird erstellt, um eine Liste mit allen Nomen und zugehörigen Artikeln zu bekommen. (Durchlaufzeit 28 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_data = False # decide, whether to scrape full data again or read an exisiting json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scrape_data:\n",
    "    #Dictionary\n",
    "    result_nomen = {}\n",
    "\n",
    "    unknown_nomen = 0\n",
    "    id = 0\n",
    "    for playlist in lon_dict.keys():\n",
    "        nomen_playlist = {}\n",
    "        for word in tqdm(lon_dict[playlist]):\n",
    "        \n",
    "            try_again = True\n",
    "            while try_again:\n",
    "                try:\n",
    "                    n = duden.get(word)\n",
    "                    try_again = False\n",
    "                except:\n",
    "                    print(f\"Error at playlist {playlist} with word {word}.\")\n",
    "                    time.sleep(2)\n",
    "        \n",
    "            if n is not None:\n",
    "                nomen_playlist[str(id)] = {\"WORT\": n.name, \"ARTIKEL\": n.article}\n",
    "                id += 1\n",
    "            else:\n",
    "                unknown_nomen += 1\n",
    "\n",
    "        result_nomen[playlist] = nomen_playlist\n",
    "\n",
    "        \n",
    "    with open(\"Nomen.json\", \"w\") as fp:\n",
    "        json.dump(result_nomen, fp, indent=4)\n",
    "        \n",
    "else:\n",
    "    with open(\"./Nomen.json\", \"r\") as f:\n",
    "        json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Nomen.json\", \"r\") as f:\n",
    "    json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einzelne Json-Dateien für Nomen (m,w,n) erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_nomen[\"Prototyp\"][\"0\"][\"WORT\"]==\"Kneipe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomen_sortiert={}\n",
    "id=0\n",
    "for playlist in result_nomen.keys():\n",
    "    nomen_g={}\n",
    "    for word in tqdm(result_nomen[playlist]):\n",
    "        if result_nomen[playlist][word][\"ARTIKEL\"] == \"der\":\n",
    "            nomen_g[str(id)]= {\"Maskuline Nomen\": result_nomen[playlist][word][\"WORT\"]}\n",
    "            id +=1\n",
    "        elif result_nomen[playlist][word][\"ARTIKEL\"] == \"die\":\n",
    "            nomen_g[str(id)]={\"Feminine Nomen\": result_nomen[playlist][word][\"WORT\"]}\n",
    "            id +=1\n",
    "        elif result_nomen[playlist][word][\"ARTIKEL\"] == \"das\":\n",
    "            nomen_g[str(id)]={\"Neutrale Nomen\": result_nomen[playlist][word][\"WORT\"]}\n",
    "            id +=1\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "\n",
    "    nomen_sortiert[playlist]= nomen_g\n",
    "with open(\"Nomen_sortiert.json\", \"w\") as fp:\n",
    "    json.dump(nomen_sortiert, fp, indent=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title tbd\n",
    "\n",
    "- Sonderzeichen in strings?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_neu = pd.read_csv(\"./gender_neu_Nomen.csv\",sep=\";\",header=None,encoding=\"utf8\")\n",
    "gender_neu = gender_neu.iloc[:, 0]\n",
    "gender_neu.columns = [\"Wort\"]\n",
    "gender_neu = list(gender_neu)\n",
    "\n",
    "with open(\"./Nomen_sortiert.json\", \"r\") as f:\n",
    "    nomen_sortiert = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True if (nomen_sortiert['Prototyp']['1']['Feminine Nomen']) in gender_neu else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = pd.DataFrame(columns=[\"Geschlecht\",\"Wort\",\"neutral\"])\n",
    "tmp = []\n",
    "playlist='Prototyp'\n",
    "for id in nomen_sortiert[playlist].keys():\n",
    "    for g in nomen_sortiert[playlist][id].keys(): # geschlecht\n",
    "        w = nomen_sortiert[playlist][id][g] # wort\n",
    "        is_gender_neutral = True if w in gender_neu else False\n",
    "\n",
    "        complete_df.loc[len(complete_df)] = [g, w, is_gender_neutral]\n",
    "        tmp.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'Maskuline Nomen': 1195,\n",
       "         'Feminine Nomen': 1092,\n",
       "         'Neutrale Nomen': 711})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(tmp)\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Geschlecht</th>\n",
       "      <th>Wort</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feminine Nomen</td>\n",
       "      <td>Kneipe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feminine Nomen</td>\n",
       "      <td>Ecke</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Maskuline Nomen</td>\n",
       "      <td>Abend</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feminine Nomen</td>\n",
       "      <td>Liebe</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feminine Nomen</td>\n",
       "      <td>Freundschaft</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Geschlecht          Wort  neutral\n",
       "0   Feminine Nomen        Kneipe    False\n",
       "1   Feminine Nomen          Ecke    False\n",
       "2  Maskuline Nomen         Abend    False\n",
       "3   Feminine Nomen         Liebe    False\n",
       "4   Feminine Nomen  Freundschaft    False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.to_json(\"./test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.loc[complete_df[\"neutral\"] == True, :]\n",
    "complete_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Example.csv', 'w', newline = '') as csvfile:\n",
    "    my_writer = csv.writer(csvfile, delimiter = ' ')\n",
    "    my_writer.writerow(complete_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pronomen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_pronomen ={}\n",
    "\n",
    "id=0\n",
    "for playlist in lop_dict.keys():\n",
    "    pronomen_playlist = {}\n",
    "    for word in tqdm(lop_dict[playlist]):\n",
    "        #männlich\n",
    "        if word.lower() in [\"er\", \"ihn\", \"derjenige\", \"derselbe\",\"wer\", \"wen\", \"wem\"]:\n",
    "            pronomen_playlist[str(id)]={\"Maskuline Pronomen\": word}\n",
    "            id +=1\n",
    "        \n",
    "        #weiblich\n",
    "        if word.lower() in [\"sie\", \"ihre\", \"dieselbe\"]:\n",
    "            pronomen_playlist[str(id)]={\"Feminine Pronomen\": word}\n",
    "            id +=1\n",
    "      \n",
    "    result_pronomen[playlist]=pronomen_playlist\n",
    "with open('Pronomen_sortiert.json', 'w') as fp:\n",
    "    json.dump(result_pronomen, fp, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = []\n",
    "for id in result_pronomen[\"Songs22\"].keys():\n",
    "    list_.append(str(result_pronomen[\"Songs22\"][id].keys()))\n",
    "list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Counter(list_)\n",
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('Pronomen_sortiert.json')\n",
    "df.to_csv('PRONOMEN.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv('PRONOMEN.csv')\n",
    "d=d.pop('Prototyp')\n",
    "d.to_csv('PRONOMEN_neu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PD= pd.json_normalize(df['Prototyp'])\n",
    "PD1= pd.json_normalize(df['Songs90er'])\n",
    "PD2= pd.json_normalize(df['Songs22'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_json('Liste_Pronomen.json')\n",
    "df1.to_csv('PRONOMEN_L.csv')\n",
    "\n",
    "df2 = pd.read_json('Nomen_sortiert.json')\n",
    "df2.to_csv('Nomen_L.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
